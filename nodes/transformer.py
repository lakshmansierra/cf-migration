import os
import json
from typing import Dict, Any
from gen_ai_hub.proxy.langchain.openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from nodes.planner import llm
from nodes.planner import LLM_DEPLOYMENT_ID
   
from utils.file_ops import read_text_file, save_dict_to_file
 
 

 
# ------------------------
# System prompt for transformer
# ------------------------
SYSTEM_PROMPT = """
ðŸ§  ROLE
 
You are a Migration Transformer, an expert responsible for converting application files from the SAP Neo environment into their Cloud Foundry (CF) equivalents.
 
Your task is to use the migration plan object (generated by a planner module) and the actual file content to intelligently produce the converted version that aligns with Cloud Foundry standards â€” while preserving the intent, logic, and configuration of the original file.
 
ðŸŽ¯ OBJECTIVE
 
Analyze the given input and automatically generate the final Cloud Foundry-compatible file content along with its correct target location and relevant notes.
 
You must use the information in the provided plan (such as reasoning, action, and target path) to guide how the conversion is done, while inferring the best transformations when possible.
 
ðŸ“¥ INPUT FORMAT
 
You will receive a single JSON object containing:
 
{
  "plan": [
    {
      "file": "<original relative path>",
      "reason": "<why this file exists and how it should migrate>",
      "action": "<one of: transform | adapt | copy | ignore | manual_review>",
      "snippets": "<trimmed sample of content>",
      "target": "<suggested Cloud Foundry target path>"
    }
  ],
  "file_content": "<the full original text content>"
}
 
ðŸ“¤ EXPECTED OUTPUT FORMAT
 
Return only one valid JSON object, in the exact structure below:
 
{
  "target_path": "<final relative path where the converted file should be stored>",
  "converted_content": "<string - new, fully converted file content>",
  "encoding": "utf-8",
  "notes": "<optional - explanation, reasoning, or manual guidance if applicable>",
  "error": "<optional - include only if the conversion cannot be completed>"
}
 
âš™ï¸ TRANSFORMATION RULES
ðŸ” 1. Interpretation
 
Analyze the "reason", "action", and "target" fields from the plan to understand what transformation is needed.
 
Use contextual understanding of the content to infer what the equivalent Cloud Foundry structure, syntax, or semantics should look like.
 
Avoid relying on hardcoded or pre-defined transformation mappings â€” infer logically based on the provided data.
 
âš’ï¸ 2. Action Behavior
 
Follow these principles when deciding what to output:
 
Action  Description
transform   Modify or rewrite the content so it fits Cloud Foundry requirements, keeping functionality equivalent.
adapt   Apply minor updates or adjustments (e.g., paths, variables, syntax) to align with Cloud Foundry conventions.
copy    Retain the content as-is, just placing it in the correct Cloud Foundry target structure.
ignore  Skip conversion â€” if this action appears, return a minimal JSON with a note indicating it is intentionally ignored.
manual_review   If the intent or structure is unclear, return a partial or placeholder conversion along with reasoning in "notes".
ðŸ§© 3. Target Inference
 
Use the "target" field from the plan to decide the fileâ€™s final path.
 
If you identify a more suitable location based on context, you may override the target â€” but explain why in the "notes" field.
 
Ensure the output path and directory hierarchy logically align with a valid Cloud Foundry project structure.
 
ðŸ§  4. Conversion Logic
 
Preserve the original functionality, intent, and structure as much as possible.
 
Update environment variables, service bindings, and runtime configurations to match Cloud Foundry practices.
 
Maintain logical readability and integrity â€” donâ€™t introduce placeholders unless absolutely necessary.
 
If there is missing information or ambiguity, respond safely with an "error" field and a short descriptive reason.
 
ðŸ§¾ OUTPUT QUALITY REQUIREMENTS
 
The "converted_content" must be a clean and complete string, representing the final transformed file ready for use.
 
The output must be valid JSON â€” no extra commentary, code fences, or markdown.
 
Do not include the original file name or unnecessary metadata.
 
When uncertainty exists, prefer clarity and caution over assumptions.
 
ðŸš« RESTRICTIONS
 
Do not output markdown, explanations, or human-readable text outside the JSON.
 
Do not hardcode Cloud Foundry templates or structures.
 
Never hallucinate content â€” base every decision strictly on the input plan and file content.
 
If unable to determine an accurate conversion, include a short, clear "error" message and reasoning.
 
 
"""
 
 
 
# ------------------------
# Initialize LLM
# ------------------------
llm = ChatOpenAI(deployment_id=LLM_DEPLOYMENT_ID, temperature=0.2)
 
 
# ------------------------
# Transform files
# ------------------------
def transform_files(repo_root: str, plan_items: list, app_name: str) -> Dict[str, str]:
    results: Dict[str, str] = {}
    items = plan_items  # plan_items is already a list
 
    for item in items:
        src_rel = item["file"]
        target_rel = item["target"]
        action = item.get("action", "manual_review")
        src_path = os.path.join(repo_root, src_rel)
 
        if not os.path.exists(src_path):
            results[target_rel] = f"# MISSING SOURCE FILE: {src_rel}\n"
            continue
 
        content = read_text_file(src_path)
        payload = json.dumps({
            "file_name": src_rel,
            "action": action,
            "file_content": content,
            "app_name": app_name
        }, indent=2)
 
        messages = [
            SystemMessage(content=SYSTEM_PROMPT),
            HumanMessage(content=payload)
        ]
        try:
            response = llm.invoke(messages)
            transformed_content = response.content
        except Exception as e:
            transformed_content = json.dumps({"error": f"llm_call_failed: {str(e)}"})
 
        results[target_rel] = transformed_content
 
    save_dict_to_file(results, os.path.join(repo_root, "transform_files_return.json"))
    return results
 
# ------------------------
# Save transformed files to disk
# ------------------------
def save_transformed_files(transformed: Dict[str, str], output_dir: str):
    for rel_path, content in transformed.items():
        out_path = os.path.join(output_dir, rel_path)
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        with open(out_path, "w", encoding="utf-8") as f:
            f.write(content)



    # # Save the function's output to a file
    # output = save_dict_to_file()
    # with open("transformer.txt", "w") as file:
    #     file.write(output)   
                