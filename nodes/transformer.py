import os
import json
from typing import Dict, Any
from gen_ai_hub.proxy.langchain.openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
    
from utils.file_ops import read_text_file, save_dict_to_file


# ------------------------
# SAP AI Core Credentials
# ------------------------
os.environ["AICORE_AUTH_URL"] = "https://gen-ai.authentication.us10.hana.ondemand.com/oauth/token"
os.environ["AICORE_CLIENT_ID"] = "sb-42a29a03-b2f4-47de-9a41-e0936be9aaf5!b256749|aicore!b164"
os.environ["AICORE_CLIENT_SECRET"] = "b5e6caee-15aa-493a-a6ac-1fef0ab6e9fe$Satg7UGYPLsz5YYeXefHpbwTfEqqCkQEbasMDPGHAgU="
os.environ["AICORE_RESOURCE_GROUP"] = "default"
os.environ["AICORE_BASE_URL"] = "https://api.ai.prod.us-east-1.aws.ml.hana.ondemand.com/v2"

# --- Model Deployment ---
LLM_DEPLOYMENT_ID = "dadede28a723f679"

# ------------------------
# System prompt for transformer
# ------------------------
SYSTEM_PROMPT = """
You are a migration transformer responsible for converting files from SAP Neo projects into their
corresponding Cloud Foundry (CF) equivalents, using only the migration plan generated by planner.py.

You will receive a JSON object that contains:
{
  "plan": [
    {
      "file": "<original Neo relative path>",
      "reason": "<why this file exists and how it should migrate>",
      "action": "<auto-decided label such as 'transform', 'adapt', 'copy', 'ignore', 'manual_review'>",
      "snippets": "<trimmed content sample>",
      "target": "<auto-inferred Cloud Foundry target path>"
    }
  ],
  "file_content": "<the full text content of the file>"
}

Your goal:
- Use the plan details and file content to produce the transformed file content automatically.
- Follow the intent described in the plan (reason + action + target).
- You do not need to follow predefined migration rules; instead, infer what’s appropriate from the data itself.
- Decide the final directory or file structure using the 'target' field, unless a better location is clear from context.

Return a **single JSON object only**, with this structure:

{
  "target_path": "<final relative path where the converted file should be stored>",
  "converted_content": "<string - new file content>",
  "encoding": "utf-8",
  "notes": "<optional - any reasoning or manual steps>",
  "error": "<optional - only if something prevents conversion>"
}

Guidelines:
- Always preserve intent and functionality of the original file.
- If you are unsure, return an error with a short note explaining why.
- Output must be valid JSON — no text before or after it.
"""



# ------------------------
# Initialize LLM
# ------------------------
llm = ChatOpenAI(deployment_id=LLM_DEPLOYMENT_ID, temperature=0.2)


# ------------------------
# Transform files
# ------------------------
def transform_files(repo_root: str, plan: Dict[str, Any], app_name: str) -> Dict[str, str]:
    results: Dict[str, str] = {}
    items = plan.get("plan", [])

    for item in items:
        src_rel = item["file"]
        target_rel = item["target"]
        action = item.get("action", "manual_review")
        src_path = os.path.join(repo_root, src_rel)

        if not os.path.exists(src_path):
            results[target_rel] = f"# MISSING SOURCE FILE: {src_rel}\n"
            continue

        content = read_text_file(src_path)
        payload = json.dumps({
            "file_name": src_rel,
            "action": action,
            "file_content": content,
            "app_name": app_name
        }, indent=2)

        messages = [
            SystemMessage(content=SYSTEM_PROMPT),
            HumanMessage(content=payload)
        ]
        try:
            response = llm.invoke(messages)
            transformed_content = response.content
        except Exception as e:
            transformed_content = json.dumps({"error": f"llm_call_failed: {str(e)}"})

        results[target_rel] = transformed_content

    save_dict_to_file(results, os.path.join(repo_root, "transform_files_return.json"))
    return results


# ------------------------
# Save transformed files to disk
# ------------------------
def save_transformed_files(transformed: Dict[str, str], output_dir: str):
    for rel_path, content in transformed.items():
        out_path = os.path.join(output_dir, rel_path)
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        with open(out_path, "w", encoding="utf-8") as f:
            f.write(content)
