import os
import json
from typing import Dict, Any
from gen_ai_hub.proxy.langchain.openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from nodes.planner import llm
from nodes.planner import LLM_DEPLOYMENT_ID
    
from utils.file_ops import read_text_file, save_dict_to_file



# ------------------------
# System prompt for transformer
# ------------------------
SYSTEM_PROMPT = """
You are a migration transformer responsible for converting files from SAP Neo projects into their
corresponding Cloud Foundry (CF) equivalents, using only the migration plan generated by planner.py.

You will receive a JSON object that contains:
{
  "plan": [
    {
      "file": "<original Neo relative path>",
      "reason": "<why this file exists and how it should migrate>",
      "action": "<auto-decided label such as 'transform', 'adapt', 'copy', 'ignore', 'manual_review'>",
      "snippets": "<trimmed content sample>",
      "target": "<auto-inferred Cloud Foundry target path>"
    }
  ],
  "file_content": "<the full text content of the file>"
}

---

### Your goal:
- Use the plan details and file content to produce the transformed file content automatically.
- Follow the intent described in the plan (`reason` + `action` + `target`).
- You do not need to follow predefined migration rules; instead, infer what’s appropriate from the data itself.
- Decide the final directory or file structure using the 'target' field, unless a better location is clear from context.

---

### Additional Rule: Add Dependencies Based on Project Purpose

- Analyze the `reason`, `snippets`, and `file_content` to infer the project's purpose.
- Based on that, include or modify a dependency descriptor file .

You have to create such files under the name in relevant with extension 

For example: .json, yaml, xml etc



- Always merge inferred dependencies without overwriting existing ones.
- Only add what’s essential for Cloud Foundry runtime compatibility



### Output Format:
Return a **single valid JSON object only**, with this structure:

```json
{
  "target_path": "<final relative path where the converted file should be stored>",
  "converted_content": "<string - new file content>",
  "encoding": "utf-8",
  "notes": "<optional - reasoning or manual follow-up steps>",
  "error": "<optional - only if something prevents conversion>"
}
```

---

### Guidelines:
- Always preserve the functionality and intent of the original file.
- Ensure added dependencies match the detected project type.
- If unsure of what dependencies to add or if the project type cannot be inferred, return an `error` field with a short note.
- Output must be **valid JSON** — no text before or after it.
"""



# ------------------------
# Initialize LLM
# ------------------------
llm = ChatOpenAI(deployment_id=LLM_DEPLOYMENT_ID, temperature=0.2)


# ------------------------
# Transform files
# ------------------------
def transform_files(repo_root: str, plan_items: list, app_name: str) -> Dict[str, str]:
    results: Dict[str, str] = {}
    items = plan_items  # plan_items is already a list

    for item in items:
        src_rel = item["file"]
        target_rel = item["target"]
        action = item.get("action", "manual_review")
        src_path = os.path.join(repo_root, src_rel)

        if not os.path.exists(src_path):
            results[target_rel] = f"# MISSING SOURCE FILE: {src_rel}\n"
            continue

        content = read_text_file(src_path)
        payload = json.dumps({
            "file_name": src_rel,
            "action": action,
            "file_content": content,
            "app_name": app_name
        }, indent=2)

        messages = [
            SystemMessage(content=SYSTEM_PROMPT),
            HumanMessage(content=payload)
        ]
        try:
            response = llm.invoke(messages)
            transformed_content = response.content
        except Exception as e:
            transformed_content = json.dumps({"error": f"llm_call_failed: {str(e)}"})

        results[target_rel] = transformed_content

    # ------------------------
    # Save results (JSON + TXT)
    # ------------------------
    json_path = os.path.join(repo_root, "transform_files_return.json")
    txt_path = os.path.join(repo_root, "transform_files_return.txt")

    # Save structured JSON
    save_dict_to_file(results, json_path)

    # Save readable TXT version
    with open(txt_path, "w", encoding="utf-8") as f:
        for target, content in results.items():
            f.write(f"=== {target} ===\n{content}\n\n")

    print(f"✅ Transformer outputs saved to:\n - {json_path}\n - {txt_path}")

    return results

# ------------------------
# Save transformed files to disk
# ------------------------
def save_transformed_files(transformed: Dict[str, str], output_dir: str):
    for rel_path, content in transformed.items():
        out_path = os.path.join(output_dir, rel_path)
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        with open(out_path, "w", encoding="utf-8") as f:
            f.write(content)